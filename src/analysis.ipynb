{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# analysis, dirty code etc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "from data_import import load_data\n",
    "from abc import ABC, abstractmethod\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from surprise import KNNWithMeans,SVD, Dataset, Reader, accuracy\n",
    "from surprise.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "# import data\n",
    "df_user, df_movie = load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data cleaning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "df_movie = df_movie[df_movie['Avg_rating']<=10]\n",
    "\n",
    "concat = lambda df, col1, col2: df[col1].astype(str) + \"_\" + df[col2].astype(str)\n",
    "\n",
    "df_movie['Title'] = concat(df_movie,'Title','Year')\n",
    "df_user['Title'] = concat(df_user,'Title','Year')\n",
    "df_user = df_user.drop(columns='Year')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Feature engineering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "# percentage difference between user rating and average rating (user-avg)\n",
    "\n",
    "df_user_temp = df_user.merge(df_movie.groupby(['Title'])['Avg_rating'].max().reset_index(), on=['Title'], how='left')\n",
    "\n",
    "df_user['Avg_user_rating_diff'] = (df_user_temp['Rating'] - df_user_temp['Avg_rating'])\n",
    "\n",
    "df_user = df_user.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "# Mapping users to numbers\n",
    "user_dict = {user: i for i, user in enumerate(df_user.User.unique())}\n",
    "movie_dict = {title: i for i, title in enumerate(df_movie.Title.unique())}\n",
    "\n",
    "df_user[['User','Title']] = df_user[['User','Title']].agg({'User': lambda x: user_dict[x], 'Title': lambda x: movie_dict[x]})\n",
    "df_movie[['Title']] = df_movie[['Title']].agg({'Title': lambda x: movie_dict[x]})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preparing final users to validate. Us."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "val_user_list = [user_dict[it] for it in ['sokoly35', 'honorciak', 'piotrr99']]\n",
    "df_user_validation = df_user[df_user['User'].isin(val_user_list)]\n",
    "\n",
    "# exclude us from df_user\n",
    "df_user = df_user[~df_user.index.isin(df_user_validation.index)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "       User  Title  Rating  Avg_user_rating_diff\n9900     82   5744     9.0                  -0.3\n9901     82   7433    10.0                   1.2\n9902     82    318     6.0                  -0.2\n9903     82   2148     3.0                   0.7\n9904     82   1171     7.0                   0.9\n...     ...    ...     ...                   ...\n32486   261   6264     8.0                   0.2\n32487   261   2469     7.0                   0.5\n32488   261   2409     7.0                   0.2\n32489   261   7447     5.0                   1.4\n32490   261   1268     7.0                  -1.8\n\n[247 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User</th>\n      <th>Title</th>\n      <th>Rating</th>\n      <th>Avg_user_rating_diff</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9900</th>\n      <td>82</td>\n      <td>5744</td>\n      <td>9.0</td>\n      <td>-0.3</td>\n    </tr>\n    <tr>\n      <th>9901</th>\n      <td>82</td>\n      <td>7433</td>\n      <td>10.0</td>\n      <td>1.2</td>\n    </tr>\n    <tr>\n      <th>9902</th>\n      <td>82</td>\n      <td>318</td>\n      <td>6.0</td>\n      <td>-0.2</td>\n    </tr>\n    <tr>\n      <th>9903</th>\n      <td>82</td>\n      <td>2148</td>\n      <td>3.0</td>\n      <td>0.7</td>\n    </tr>\n    <tr>\n      <th>9904</th>\n      <td>82</td>\n      <td>1171</td>\n      <td>7.0</td>\n      <td>0.9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32486</th>\n      <td>261</td>\n      <td>6264</td>\n      <td>8.0</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>32487</th>\n      <td>261</td>\n      <td>2469</td>\n      <td>7.0</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>32488</th>\n      <td>261</td>\n      <td>2409</td>\n      <td>7.0</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>32489</th>\n      <td>261</td>\n      <td>7447</td>\n      <td>5.0</td>\n      <td>1.4</td>\n    </tr>\n    <tr>\n      <th>32490</th>\n      <td>261</td>\n      <td>1268</td>\n      <td>7.0</td>\n      <td>-1.8</td>\n    </tr>\n  </tbody>\n</table>\n<p>247 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "class BaseRecommender(ABC):\n",
    "    def __init__(self, df_user: pd.DataFrame, df_movie: pd.DataFrame):\n",
    "        self.df_user = df_user\n",
    "        self.df_movie = df_movie\n",
    "\n",
    "    \"\"\" Base abstract class for recommendation techniques.\"\"\"\n",
    "    def train(self, df_user: Union[pd.DataFrame, None], **kwargs):\n",
    "        raise NotImplementedError\n",
    "    def predict(self, df_user: pd.DataFrame, num_of_recomendations: int, **kwargs):\n",
    "        raise NotImplementedError"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "# decode users and movies\n",
    "def decode(df):\n",
    "    user_dict_decoder = {val: key for key, val in user_dict.items()}\n",
    "    movie_dict_decoder = {val: key for key, val in movie_dict.items()}\n",
    "    df_cols = df.columns\n",
    "    if 'User' in df_cols:\n",
    "        df['User'] = df['User'].agg(lambda x: user_dict_decoder[x])\n",
    "    if 'Title' in df_cols:\n",
    "        df['Title'] = df['Title'].agg(lambda x: movie_dict_decoder[x])\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. User cold start\n",
    "* recommendation based on popularity and overall rating of the movie for users with not many rated movies\n",
    "* we have no data about the user (age, gender, ...) so we don't use it as a feature in collaborative filtering."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "class UCSRecommender(BaseRecommender):\n",
    "    \"\"\" user cold start recommender.\n",
    "    Take n_top_movies and recommend them in order based on Avg_rating.\"\"\"\n",
    "    recommendation_table = None\n",
    "\n",
    "    def train(self, df_user: Union[pd.DataFrame, None], n_top_movies: int = 20, **kwargs):\n",
    "        self.recommendation_table = df_movie.groupby(['Title'])[['Avg_rating', 'Number_of_ratings']].min().reset_index().sort_values('Number_of_ratings', ascending=False).head(n_top_movies).sort_values('Avg_rating', ascending=False)\n",
    "\n",
    "    def predict(self, df_user: pd.DataFrame, num_of_recomendations: int, **kwargs):\n",
    "        recommendations = pd.DataFrame(columns=['User', 'Title'])\n",
    "        for user in df_user['User'].unique():\n",
    "            recommendations_for_user = self.recommendation_table.head(num_of_recomendations)[['Title']]\n",
    "            recommendations_for_user['User'] = user\n",
    "            recommendations = pd.concat([recommendations, recommendations_for_user])\n",
    "        return recommendations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "           User                                        Title\n5744  honorciak                    Skazani na Shawshank_1994\n7433  honorciak                            Zielona mila_1999\n4163  honorciak                              Nietykalni_2011\n1867  honorciak                            Forrest Gump_1994\n5264  honorciak                            Pulp Fiction_1994\n3621  honorciak                         Milczenie owiec_1991\n3258  honorciak                         Leon zawodowiec_1994\n6077  honorciak                        Szeregowiec Ryan_1998\n2006  honorciak                               Gladiator_2000\n7177  honorciak  Władca Pierścieni: Drużyna Pierścienia_2001\n5744   piotrr99                    Skazani na Shawshank_1994\n7433   piotrr99                            Zielona mila_1999\n4163   piotrr99                              Nietykalni_2011\n1867   piotrr99                            Forrest Gump_1994\n5264   piotrr99                            Pulp Fiction_1994\n3621   piotrr99                         Milczenie owiec_1991\n3258   piotrr99                         Leon zawodowiec_1994\n6077   piotrr99                        Szeregowiec Ryan_1998\n2006   piotrr99                               Gladiator_2000\n7177   piotrr99  Władca Pierścieni: Drużyna Pierścienia_2001\n5744   sokoly35                    Skazani na Shawshank_1994\n7433   sokoly35                            Zielona mila_1999\n4163   sokoly35                              Nietykalni_2011\n1867   sokoly35                            Forrest Gump_1994\n5264   sokoly35                            Pulp Fiction_1994\n3621   sokoly35                         Milczenie owiec_1991\n3258   sokoly35                         Leon zawodowiec_1994\n6077   sokoly35                        Szeregowiec Ryan_1998\n2006   sokoly35                               Gladiator_2000\n7177   sokoly35  Władca Pierścieni: Drużyna Pierścienia_2001",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User</th>\n      <th>Title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5744</th>\n      <td>honorciak</td>\n      <td>Skazani na Shawshank_1994</td>\n    </tr>\n    <tr>\n      <th>7433</th>\n      <td>honorciak</td>\n      <td>Zielona mila_1999</td>\n    </tr>\n    <tr>\n      <th>4163</th>\n      <td>honorciak</td>\n      <td>Nietykalni_2011</td>\n    </tr>\n    <tr>\n      <th>1867</th>\n      <td>honorciak</td>\n      <td>Forrest Gump_1994</td>\n    </tr>\n    <tr>\n      <th>5264</th>\n      <td>honorciak</td>\n      <td>Pulp Fiction_1994</td>\n    </tr>\n    <tr>\n      <th>3621</th>\n      <td>honorciak</td>\n      <td>Milczenie owiec_1991</td>\n    </tr>\n    <tr>\n      <th>3258</th>\n      <td>honorciak</td>\n      <td>Leon zawodowiec_1994</td>\n    </tr>\n    <tr>\n      <th>6077</th>\n      <td>honorciak</td>\n      <td>Szeregowiec Ryan_1998</td>\n    </tr>\n    <tr>\n      <th>2006</th>\n      <td>honorciak</td>\n      <td>Gladiator_2000</td>\n    </tr>\n    <tr>\n      <th>7177</th>\n      <td>honorciak</td>\n      <td>Władca Pierścieni: Drużyna Pierścienia_2001</td>\n    </tr>\n    <tr>\n      <th>5744</th>\n      <td>piotrr99</td>\n      <td>Skazani na Shawshank_1994</td>\n    </tr>\n    <tr>\n      <th>7433</th>\n      <td>piotrr99</td>\n      <td>Zielona mila_1999</td>\n    </tr>\n    <tr>\n      <th>4163</th>\n      <td>piotrr99</td>\n      <td>Nietykalni_2011</td>\n    </tr>\n    <tr>\n      <th>1867</th>\n      <td>piotrr99</td>\n      <td>Forrest Gump_1994</td>\n    </tr>\n    <tr>\n      <th>5264</th>\n      <td>piotrr99</td>\n      <td>Pulp Fiction_1994</td>\n    </tr>\n    <tr>\n      <th>3621</th>\n      <td>piotrr99</td>\n      <td>Milczenie owiec_1991</td>\n    </tr>\n    <tr>\n      <th>3258</th>\n      <td>piotrr99</td>\n      <td>Leon zawodowiec_1994</td>\n    </tr>\n    <tr>\n      <th>6077</th>\n      <td>piotrr99</td>\n      <td>Szeregowiec Ryan_1998</td>\n    </tr>\n    <tr>\n      <th>2006</th>\n      <td>piotrr99</td>\n      <td>Gladiator_2000</td>\n    </tr>\n    <tr>\n      <th>7177</th>\n      <td>piotrr99</td>\n      <td>Władca Pierścieni: Drużyna Pierścienia_2001</td>\n    </tr>\n    <tr>\n      <th>5744</th>\n      <td>sokoly35</td>\n      <td>Skazani na Shawshank_1994</td>\n    </tr>\n    <tr>\n      <th>7433</th>\n      <td>sokoly35</td>\n      <td>Zielona mila_1999</td>\n    </tr>\n    <tr>\n      <th>4163</th>\n      <td>sokoly35</td>\n      <td>Nietykalni_2011</td>\n    </tr>\n    <tr>\n      <th>1867</th>\n      <td>sokoly35</td>\n      <td>Forrest Gump_1994</td>\n    </tr>\n    <tr>\n      <th>5264</th>\n      <td>sokoly35</td>\n      <td>Pulp Fiction_1994</td>\n    </tr>\n    <tr>\n      <th>3621</th>\n      <td>sokoly35</td>\n      <td>Milczenie owiec_1991</td>\n    </tr>\n    <tr>\n      <th>3258</th>\n      <td>sokoly35</td>\n      <td>Leon zawodowiec_1994</td>\n    </tr>\n    <tr>\n      <th>6077</th>\n      <td>sokoly35</td>\n      <td>Szeregowiec Ryan_1998</td>\n    </tr>\n    <tr>\n      <th>2006</th>\n      <td>sokoly35</td>\n      <td>Gladiator_2000</td>\n    </tr>\n    <tr>\n      <th>7177</th>\n      <td>sokoly35</td>\n      <td>Władca Pierścieni: Drużyna Pierścienia_2001</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of usage\n",
    "ucs_recommender = UCSRecommender(df_user, df_movie)\n",
    "ucs_recommender.train(df_user)\n",
    "recommendations = ucs_recommender.fit(df_user=df_user_validation, num_of_recomendations=10)\n",
    "\n",
    "decode(recommendations)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Collaborative filtering\n",
    "* user similarity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "# TODO:\n",
    "\n",
    "# KNN\n",
    "similarity = {\n",
    "    \"name\": \"cosine\",\n",
    "    \"user_based\": False,  # item-based similarity\n",
    "}\n",
    "algo_KNN = KNNWithMeans(sim_options = similarity)\n",
    "\n",
    "# SVD\n",
    "algo_SVD = SVD()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale = (1,10))\n",
    "rating_df = Dataset.load_from_df(df_user[['User','Title', 'Rating']], reader)\n",
    "\n",
    "# from surprise.model_selection import cross_validate\n",
    "# cross_validate_KNN = cross_validate(algo_KNN, rating_df, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "# cross_validate_SVD = cross_validate(algo_SVD, rating_df, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "# define train test function\n",
    "def train_test_algo(algo, label):\n",
    "    training_set, testing_set = train_test_split(rating_df, test_size = 0.2)\n",
    "    algo.fit(training_set)\n",
    "    test_output = algo.test(testing_set)\n",
    "    test_df = pd.DataFrame(test_output)\n",
    "\n",
    "    print(\"RMSE -\",label, accuracy.rmse(test_output, verbose = False))\n",
    "    print(\"MAE -\", label, accuracy.mae(test_output, verbose=False))\n",
    "    print(\"MSE -\", label, accuracy.mse(test_output, verbose=False))\n",
    "\n",
    "    return test_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "test_size=0 should be strictly greater than 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[147], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m train_test_KNN \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_test_algo\u001B[49m\u001B[43m(\u001B[49m\u001B[43malgo_KNN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43malgo_KNN\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(train_test_KNN\u001B[38;5;241m.\u001B[39mhead())\n\u001B[0;32m      3\u001B[0m train_test_SVD \u001B[38;5;241m=\u001B[39m train_test_algo(algo_SVD, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124malgo_SVD\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[146], line 3\u001B[0m, in \u001B[0;36mtrain_test_algo\u001B[1;34m(algo, label)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_test_algo\u001B[39m(algo, label):\n\u001B[1;32m----> 3\u001B[0m     training_set, testing_set \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_test_split\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrating_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     algo\u001B[38;5;241m.\u001B[39mfit(training_set)\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;66;03m# test_output = algo.test(testing_set)\u001B[39;00m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;66;03m# test_df = pd.DataFrame(test_output)\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \n\u001B[0;32m      8\u001B[0m     \u001B[38;5;66;03m# print(\"RMSE -\",label, accuracy.rmse(test_output, verbose = False))\u001B[39;00m\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;66;03m# print(\"MAE -\", label, accuracy.mae(test_output, verbose=False))\u001B[39;00m\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;66;03m# print(\"MSE -\", label, accuracy.mse(test_output, verbose=False))\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\aoud\\lib\\site-packages\\surprise\\model_selection\\split.py:348\u001B[0m, in \u001B[0;36mtrain_test_split\u001B[1;34m(data, test_size, train_size, random_state, shuffle)\u001B[0m\n\u001B[0;32m    316\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_test_split\u001B[39m(\n\u001B[0;32m    317\u001B[0m     data, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, train_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    318\u001B[0m ):\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;124;03m\"\"\"Split a dataset into trainset and testset.\u001B[39;00m\n\u001B[0;32m    320\u001B[0m \n\u001B[0;32m    321\u001B[0m \u001B[38;5;124;03m    See an example in the :ref:`User Guide <train_test_split_example>`.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;124;03m            parameter. Shuffling is not done in-place. Default is ``True``.\u001B[39;00m\n\u001B[0;32m    347\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 348\u001B[0m     ss \u001B[38;5;241m=\u001B[39m \u001B[43mShuffleSplit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    355\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(ss\u001B[38;5;241m.\u001B[39msplit(data))\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\aoud\\lib\\site-packages\\surprise\\model_selection\\split.py:228\u001B[0m, in \u001B[0;36mShuffleSplit.__init__\u001B[1;34m(self, n_splits, test_size, train_size, random_state, shuffle)\u001B[0m\n\u001B[0;32m    224\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    225\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_splits = \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m should be strictly greater than \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(n_splits)\n\u001B[0;32m    226\u001B[0m     )\n\u001B[0;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m test_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m test_size \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 228\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    229\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_size=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m should be strictly greater than \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(test_size)\n\u001B[0;32m    230\u001B[0m     )\n\u001B[0;32m    232\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m train_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m train_size \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    233\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    234\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_size=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m should be strictly greater than \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(train_size)\n\u001B[0;32m    235\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: test_size=0 should be strictly greater than 0"
     ]
    }
   ],
   "source": [
    "train_test_KNN = train_test_algo(algo_KNN, \"algo_KNN\")\n",
    "print(train_test_KNN.head())\n",
    "train_test_SVD = train_test_algo(algo_SVD, \"algo_SVD\")\n",
    "print(train_test_SVD.head())\n",
    "\n",
    "# as we can see SVD does better job, so we process with SVD."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "def prediction(algo, users_K):\n",
    "    pred_list = []\n",
    "    for userId in range(1, users_K):\n",
    "        for movieId in range(1, len(df_movie.Title.unique())):\n",
    "            rating = algo.predict(userId, movieId).est\n",
    "            pred_list.append([userId, movieId, rating])\n",
    "    pred_df = pd.DataFrame(pred_list, columns = ['userId', 'movieId', 'rating'])\n",
    "    return pred_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# def top_recommendations(pred_df, top_N):\n",
    "#     link_movie = pd.merge(pred_df, links_df, how='inner', left_on='movieId', right_on='movieId')\n",
    "#     recommended_movie = pd.merge(link_movie, movie_df, how='left', left_on='imdbId', right_on='imdb_id')[['userId', 'movieId', 'rating', 'movieId','imdb_id','title']]\n",
    "#     sorted_df = recommended_movie.groupby(('userId'), as_index = False).apply(lambda x: x.sort_values(['rating'], ascending = False)).reset_index(drop=True)\n",
    "#     top_recommended_movies = sorted_df.groupby('userId').head(top_N)\n",
    "#     return sorted_df, top_recommended_movies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "       userId  movieId    rating\n0           1        1  1.000000\n1           1        2  7.166667\n2           1        3  7.098803\n3           1        4  5.566667\n4           1        5  4.733333\n...       ...      ...       ...\n69592       9     7729  5.969287\n69593       9     7730  7.969287\n69594       9     7731  8.168812\n69595       9     7732  9.135745\n69596       9     7733  6.000000\n\n[69597 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>7.166667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>7.098803</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>5.566667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>4.733333</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>69592</th>\n      <td>9</td>\n      <td>7729</td>\n      <td>5.969287</td>\n    </tr>\n    <tr>\n      <th>69593</th>\n      <td>9</td>\n      <td>7730</td>\n      <td>7.969287</td>\n    </tr>\n    <tr>\n      <th>69594</th>\n      <td>9</td>\n      <td>7731</td>\n      <td>8.168812</td>\n    </tr>\n    <tr>\n      <th>69595</th>\n      <td>9</td>\n      <td>7732</td>\n      <td>9.135745</td>\n    </tr>\n    <tr>\n      <th>69596</th>\n      <td>9</td>\n      <td>7733</td>\n      <td>6.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>69597 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN predictions\n",
    "pred_KNN = prediction(algo_KNN, 10)\n",
    "pred_KNN\n",
    "# recommended_movies_KNN, top_recommended_movies_KNN = top_recommendations(pred_KNN, 3)\n",
    "# ## SVD predictions\n",
    "# pred_SVD = prediction(algo_SVD, 10)\n",
    "# recommended_movies_SVD, top_recommended_movies_SVD = top_recommendations(pred_SVD, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "class CFRecommender(BaseRecommender):\n",
    "    def __init__(self, df_user, df_movie):\n",
    "        super(CFRecommender, self).__init__(df_user, df_movie)\n",
    "        self.algo_SVD = SVD()\n",
    "        # rating scale\n",
    "        # reader = Reader(rating_scale = (1,10))\n",
    "        # self.rating_df = Dataset.load_from_df(df_user[['User','Title', 'Rating']], reader)\n",
    "\n",
    "    def train(self, df_user: Union[pd.DataFrame, None], n_top_movies: int = 20, **kwargs):\n",
    "         reader = Reader(rating_scale = (1,10))\n",
    "         self.rating_df = Dataset.load_from_df(df_user[['User','Title', 'Rating']], reader)\n",
    "\n",
    "         self.algo_SVD.fit(self.rating_df.build_full_trainset())\n",
    "\n",
    "    def predict(self, df_user: pd.DataFrame, num_of_recomendations: int, **kwargs):\n",
    "        recommendations = pd.DataFrame(columns = ['User', 'Title', 'Rating'])\n",
    "        for user in df_user['User'].unique():\n",
    "\n",
    "            user_movies = df_user[df_user['User'] == user]['Title'].unique()\n",
    "\n",
    "            # predict value for each movie in dataset.\n",
    "            pred_list = []\n",
    "            for movie in range(1, len(df_movie.Title.unique())):\n",
    "                rating = self.algo_SVD.predict(user, movie).est\n",
    "                pred_list.append([user, movie, rating])\n",
    "\n",
    "            recommendations_for_user = pd.DataFrame(pred_list, columns = ['User', 'Title', 'Rating'])\n",
    "\n",
    "            # remove already watched movies from recommendations\n",
    "            recommendations_for_user = recommendations_for_user[~ recommendations_for_user['Title'].isin(user_movies)].sort_values('Rating',ascending=False).head(num_of_recomendations)\n",
    "            recommendations = pd.concat([recommendations, recommendations_for_user])\n",
    "        return recommendations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "data": {
      "text/plain": "           User                                Title    Rating\n5263  honorciak                    Pulp Fiction_1994  8.519361\n1535  honorciak        Dwunastu gniewnych ludzi_1957  8.440207\n3297  honorciak                Lista Schindlera_1993  8.437749\n4162  honorciak                      Nietykalni_2011  8.372387\n3338  honorciak      Lot nad kukułczym gniazdem_1975  8.342050\n5857   piotrr99  Spirited Away: W krainie Bogów_2001  8.672691\n2005   piotrr99                       Gladiator_2000  8.481566\n6848   piotrr99                        Whiplash_2014  8.465827\n3297   piotrr99                Lista Schindlera_1993  8.431235\n6076   piotrr99                Szeregowiec Ryan_1998  8.403267\n5743   sokoly35            Skazani na Shawshank_1994  8.862510\n4162   sokoly35                      Nietykalni_2011  8.501149\n7432   sokoly35                    Zielona mila_1999  8.492047\n2091   sokoly35                     Gran Torino_2008  8.449453\n5263   sokoly35                    Pulp Fiction_1994  8.377300",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>User</th>\n      <th>Title</th>\n      <th>Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5263</th>\n      <td>honorciak</td>\n      <td>Pulp Fiction_1994</td>\n      <td>8.519361</td>\n    </tr>\n    <tr>\n      <th>1535</th>\n      <td>honorciak</td>\n      <td>Dwunastu gniewnych ludzi_1957</td>\n      <td>8.440207</td>\n    </tr>\n    <tr>\n      <th>3297</th>\n      <td>honorciak</td>\n      <td>Lista Schindlera_1993</td>\n      <td>8.437749</td>\n    </tr>\n    <tr>\n      <th>4162</th>\n      <td>honorciak</td>\n      <td>Nietykalni_2011</td>\n      <td>8.372387</td>\n    </tr>\n    <tr>\n      <th>3338</th>\n      <td>honorciak</td>\n      <td>Lot nad kukułczym gniazdem_1975</td>\n      <td>8.342050</td>\n    </tr>\n    <tr>\n      <th>5857</th>\n      <td>piotrr99</td>\n      <td>Spirited Away: W krainie Bogów_2001</td>\n      <td>8.672691</td>\n    </tr>\n    <tr>\n      <th>2005</th>\n      <td>piotrr99</td>\n      <td>Gladiator_2000</td>\n      <td>8.481566</td>\n    </tr>\n    <tr>\n      <th>6848</th>\n      <td>piotrr99</td>\n      <td>Whiplash_2014</td>\n      <td>8.465827</td>\n    </tr>\n    <tr>\n      <th>3297</th>\n      <td>piotrr99</td>\n      <td>Lista Schindlera_1993</td>\n      <td>8.431235</td>\n    </tr>\n    <tr>\n      <th>6076</th>\n      <td>piotrr99</td>\n      <td>Szeregowiec Ryan_1998</td>\n      <td>8.403267</td>\n    </tr>\n    <tr>\n      <th>5743</th>\n      <td>sokoly35</td>\n      <td>Skazani na Shawshank_1994</td>\n      <td>8.862510</td>\n    </tr>\n    <tr>\n      <th>4162</th>\n      <td>sokoly35</td>\n      <td>Nietykalni_2011</td>\n      <td>8.501149</td>\n    </tr>\n    <tr>\n      <th>7432</th>\n      <td>sokoly35</td>\n      <td>Zielona mila_1999</td>\n      <td>8.492047</td>\n    </tr>\n    <tr>\n      <th>2091</th>\n      <td>sokoly35</td>\n      <td>Gran Torino_2008</td>\n      <td>8.449453</td>\n    </tr>\n    <tr>\n      <th>5263</th>\n      <td>sokoly35</td>\n      <td>Pulp Fiction_1994</td>\n      <td>8.377300</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_recommender = CFRecommender(pd.concat([df_user, df_user_validation]), df_movie)\n",
    "cf_recommender.train(pd.concat([df_user, df_user_validation]))\n",
    "recommendations = cf_recommender.predict(df_user_validation, 5)\n",
    "decode(recommendations)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Content based\n",
    "* movie similarity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Final model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}